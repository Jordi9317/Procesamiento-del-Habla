{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ü§ó Aplicaciones pr√°cticas de Transformers con Hugging Face\n",
        "\n",
        "En esta clase vamos a usar modelos preentrenados en espa√±ol para resolver tareas reales de Procesamiento del Lenguaje Natural (PLN), sin necesidad de entrenar modelos desde cero.\n",
        "\n",
        "Trabajaremos con la librer√≠a `transformers` de Hugging Face, que permite usar modelos de tipo BERT, GPT y similares en muy pocas l√≠neas de c√≥digo.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "jFLeMnvKZbE2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZ_CCTg1ZZMX"
      },
      "outputs": [],
      "source": [
        "# Instalaci√≥n de Hugging Face Transformers (solo una vez)\n",
        "!pip install -q transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Cargando el pipeline de Hugging Face\n",
        "\n",
        "Hugging Face proporciona \"pipelines\" que encapsulan todo el proceso: tokenizaci√≥n, modelo y decodificaci√≥n. Solo ten√©s que indicar qu√© tarea quer√©s hacer.\n"
      ],
      "metadata": {
        "id": "eLn8knQiZktz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "2-F5MJPqZleF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. An√°lisis de sentimiento en espa√±ol\n",
        "\n",
        "Vamos a usar un modelo entrenado para identificar si una frase expresa un **sentimiento positivo o negativo**. Este modelo fue entrenado con tweets en espa√±ol."
      ],
      "metadata": {
        "id": "ByWX-6UqZsGE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment = pipeline(\"sentiment-analysis\", model=\"finiteautomata/beto-sentiment-analysis\")"
      ],
      "metadata": {
        "id": "1Je8EvD0ip1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frases = [\n",
        "    \"Este lugar est√° buen√≠simo, la atenci√≥n de diez\",\n",
        "    \"Una experiencia horrible, me quiero ir\",\n",
        "    \"Zafa, pero esperaba m√°s\",\n",
        "    \"Recomiendo totalmente este producto\",\n",
        "    \"Nunca m√°s compro ac√°\"\n",
        "]"
      ],
      "metadata": {
        "id": "k5xNiIU9Zrz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for frase in frases:\n",
        "    print(f\"{frase} ‚Üí {sentiment(frase)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "7ic9Jokw76dr",
        "outputId": "6a6520c8-1b73-4194-b2bf-a269b4ec949e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Este lugar est√° buen√≠simo, la atenci√≥n de diez ‚Üí [{'label': 'POS', 'score': 0.9988070726394653}]\n",
            "Una experiencia horrible, me quiero ir ‚Üí [{'label': 'NEG', 'score': 0.9991808533668518}]\n",
            "Zafa, pero esperaba m√°s ‚Üí [{'label': 'NEG', 'score': 0.9256047010421753}]\n",
            "Recomiendo totalmente este producto ‚Üí [{'label': 'POS', 'score': 0.9985804557800293}]\n",
            "Nunca m√°s compro ac√° ‚Üí [{'label': 'NEG', 'score': 0.9992826581001282}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Clasificaci√≥n de texto por tema (*zero-shot*)\n",
        "\n",
        "¬øQuer√©s clasificar frases por categor√≠as sin entrenar un modelo? ¬°Esto es posible gracias al aprendizaje **zero-shot**!\n",
        "\n",
        "El modelo puede asociar un texto con una o m√°s **etiquetas** sugeridas por vos, aunque nunca fue entrenado espec√≠ficamente para esas clases."
      ],
      "metadata": {
        "id": "jLvgJTdNZyoM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = pipeline(\"zero-shot-classification\", model=\"Recognai/bert-base-spanish-wwm-cased-xnli\")"
      ],
      "metadata": {
        "id": "g4DDvK_aixWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"Lionel Messi firm√≥ contrato con el Inter Miami y debutar√° esta semana.\"\n",
        "\n",
        "etiquetas = [\"deportes\", \"econom√≠a\", \"pol√≠tica\", \"espect√°culos\"]\n",
        "\n",
        "print(classifier(texto, candidate_labels=etiquetas))"
      ],
      "metadata": {
        "id": "UyR37nNRZ0xb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cd6b0ad-0252-420e-fdd7-a0c4aeed7577"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'sequence': 'Lionel Messi firm√≥ contrato con el Inter Miami y debutar√° esta semana.', 'labels': ['deportes', 'espect√°culos', 'pol√≠tica', 'econom√≠a'], 'scores': [0.516789436340332, 0.2758041322231293, 0.1318969577550888, 0.0755094587802887]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Resumen autom√°tico de textos\n",
        "\n",
        "Este pipeline toma un texto largo y genera un resumen breve en espa√±ol. Ideal para noticias, informes o textos descriptivos.\n",
        "\n",
        "Usamos un modelo BERT2BERT adaptado al espa√±ol."
      ],
      "metadata": {
        "id": "4GQztuQRZ4fi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summarizer = pipeline(\n",
        "    \"summarization\",\n",
        "    model=\"csebuetnlp/mT5_multilingual_XLSum\",\n",
        "    tokenizer=\"csebuetnlp/mT5_multilingual_XLSum\"\n",
        ")"
      ],
      "metadata": {
        "id": "xVeW86swi4el"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parrafo = \"\"\"\n",
        "El Ministerio de Salud confirm√≥ hoy que se ha logrado una reducci√≥n sostenida de casos de dengue en las √∫ltimas semanas.\n",
        "Las campa√±as de prevenci√≥n, sumadas a la llegada del fr√≠o, habr√≠an contribuido a esta baja. Sin embargo, se pide a la poblaci√≥n mantener las precauciones.\n",
        "\"\"\"\n",
        "\n",
        "resumen = summarizer(parrafo, max_length=50, min_length=20, do_sample=False)\n",
        "print(resumen[0]['summary_text'])\n"
      ],
      "metadata": {
        "id": "3akyvUJ8Z6g7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "56e45f7a-221f-431d-dc80-fcf982196f92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El n√∫mero de casos de dengue en Estados Unidos alcanz√≥ un nuevo r√©cord.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"\"\"\n",
        "La inflaci√≥n en Argentina ha mostrado una leve desaceleraci√≥n en el √∫ltimo mes, seg√∫n el informe del INDEC.\n",
        "Sin embargo, los analistas advierten que la tendencia a√∫n no se revierte, y que podr√≠an esperarse aumentos para el pr√≥ximo trimestre.\n",
        "\"\"\"\n",
        "\n",
        "resumen = summarizer(texto, max_length=60, min_length=25, do_sample=False)\n",
        "print(resumen[0]['summary_text'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "-PTb3CEpj8vd",
        "outputId": "9d1e592f-c8ff-4381-dca0-a21aeaa55947"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El Fondo Monetario Internacional (INDEC) dijo que la inflaci√≥n en Argentina se ha recuperado de una desaceleraci√≥n en el √∫ltimo mes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Traducci√≥n autom√°tica (Espa√±ol ‚Üí Ingl√©s)\n",
        "\n",
        "Tambi√©n podemos usar modelos preentrenados para **traducir textos**. En este caso, usaremos uno especializado para traducir del espa√±ol al ingl√©s.\n"
      ],
      "metadata": {
        "id": "wi8qYvCBZ7PU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-es-en\")"
      ],
      "metadata": {
        "id": "UwMrWPLBkKKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"La inteligencia artificial est√° cambiando el mundo.\"\n",
        "\n",
        "print(translator(texto)[0]['translation_text'])\n"
      ],
      "metadata": {
        "id": "6Hs_GEE2Z-3Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f7481b37-5709-4e3c-9073-5c91551ac1b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Artificial intelligence is changing the world.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Generaci√≥n de texto en espa√±ol (GPT)\n",
        "\n",
        "Con un modelo tipo GPT entrenado en espa√±ol, podemos **generar texto a partir de un inicio dado**. Ideal para escribir contenido creativo, continuar frases, etc.\n"
      ],
      "metadata": {
        "id": "Aym3GgYraBhw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator = pipeline(\"text-generation\", model=\"PlanTL-GOB-ES/gpt2-base-bne\")"
      ],
      "metadata": {
        "id": "T_8fzsSBkOwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Un dinosaurio est√°\"\n",
        "\n",
        "resultado = generator(prompt, max_length=50, num_return_sequences=1)\n",
        "print(resultado[0]['generated_text'])\n"
      ],
      "metadata": {
        "id": "QifU_lmfZ_50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3afe4665-9226-4480-b718-14765ccef8e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=51) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Un dinosaurio est√° hecho de un sistema de construcci√≥n en el que el coraz√≥n se divide en dos partes, una que puede... \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Reflexi√≥n y discusi√≥n\n",
        "\n",
        "- ¬øCu√°l de estos pipelines te pareci√≥ m√°s sorprendente o √∫til?\n",
        "    El pipeline de clasificaci√≥n de texto por tema (zero-shot) me parece muy interesante. El resumen autom√°tico tambi√©n es muy √∫til para procesar r√°pidamente grandes cantidades de texto.\n",
        "- ¬øCre√©s que estas herramientas podr√≠an usarse en un proyecto real? ¬øEn cu√°l?\n",
        "    Estoy seguro que lo puedo aplicar en alguno de mis proyectos como podrian ser:\n",
        "\n",
        "    *1)Traducci√≥n autom√°tica*: Localizaci√≥n de contenido, comunicaci√≥n multiling√ºe b√°sica, traducci√≥n r√°pida de documentos.\n",
        "    \n",
        "    *2)Generaci√≥n de texto*: Creaci√≥n de contenido creativo, asistencia en la redacci√≥n de correos electr√≥nicos o art√≠culos, generaci√≥n de descripciones de productos (con revisi√≥n humana).\n",
        "- ¬øNotaste errores o sesgos? ¬øPor qu√© cre√©s que aparecen?\n",
        "    S√≠, se pueden notar posibles \"errores\" o comportamientos inesperados, especialmente en el resumen autom√°tico. Por ejemplo, en el resumen del p√°rrafo sobre el dengue, el modelo gener√≥ un resumen sobre casos de dengue en Estados Unidos, lo cual no estaba en el texto original. En el resumen sobre la inflaci√≥n, mencion√≥ al FMI en lugar del INDEC.\n",
        "\n",
        "    Estos errores o sesgos pueden aparecer por varias razones:\n",
        "\n",
        "    **Datos de entrenamiento**: Los modelos aprenden de los datos con los que fueron entrenados. Si esos datos contienen sesgos (por ejemplo, ciertos estereotipos, o informaci√≥n desactualizada/incorrecta), el modelo puede reflejarlos. En el caso de la generaci√≥n de texto o resumen, si el modelo fue entrenado con datos de diferentes fuentes o regiones, puede generar informaci√≥n que no se alinea exactamente con el texto de entrada si hay informaci√≥n contradictoria o si el modelo prioriza cierta informaci√≥n de su entrenamiento general.\n",
        "\n",
        "    **Limitaciones del modelo**: Aunque son muy potentes, los modelos no \"entienden\" el texto de la misma manera que un humano. Operan bas√°ndose en patrones estad√≠sticos y la probabilidad de secuencias de palabras. Esto puede llevar a res√∫menes que no capturan el significado exacto o a traducciones que no son perfectamente idiom√°ticas.\n",
        "\n",
        "    **Naturaleza de la tarea**: Tareas como el resumen son intr√≠nsecamente complejas y subjetivas. Lo que es un \"buen\" resumen puede variar. Los modelos generan un resumen basado en lo que es estad√≠sticamente probable que sea relevante, pero no siempre aciertan.\n",
        "\n",
        "    **Configuraci√≥n de los par√°metros**: Par√°metros como max_length o min_length en el resumen pueden influir en la calidad y coherencia del resultado.\n",
        "    Es crucial recordar que, si bien estos modelos son herramientas poderosas, a menudo requieren supervisi√≥n humana, especialmente en aplicaciones donde la precisi√≥n y la ausencia de sesgos son cr√≠ticas.\n",
        "\n"
      ],
      "metadata": {
        "id": "fH5RSqBDaFul"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Actividad libre (opcional si hay tiempo)\n",
        "\n",
        "Explor√° uno de los pipelines y dise√±√° tu propio experimento:\n",
        "\n",
        "- Prob√° frases con sarcasmo o jergas locales.\n",
        "- Resum√≠ un art√≠culo de Wikipedia.\n",
        "- Traduc√≠ algo complejo (tecnol√≥gico, po√©tico, etc.).\n",
        "- Complet√° una frase usando estilo formal o informal.\n",
        "\n",
        "Al final compartimos los hallazgos m√°s interesantes con el grupo üëÄ\n",
        "\n"
      ],
      "metadata": {
        "id": "gC5dHmTaaOO7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# An√°lisis de sentimiento en espa√±ol\n",
        "\n",
        "  Pruebo frases con sarcasmo o jergas locales estilo Pepe Mujica."
      ],
      "metadata": {
        "id": "RzgtvEA2zsi9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frases2 = [\n",
        "    \"Pa' serte franco, esto est√° de novela, che\",\n",
        "    \"Mir√°, esto es un desastre, ni al peor enemigo se lo recomiendo\",\n",
        "    \"No est√° ni tan mal ni tan bien... como pa' zafar\",\n",
        "    \"Una joyita, lo digo con el coraz√≥n en la mano\",\n",
        "    \"Esto no tiene vuelta, fue un clavo tremendo\",\n",
        "    \"Le ponen garra, se nota, eso vale m√°s que mil estrellas\",\n",
        "    \"Una decepci√≥n b√°rbara, esperaba otra cosa\",\n",
        "    \"Est√° bueno, sencillo pero cumplidor, como tiene que ser\",\n",
        "    \"Nunca m√°s caigo en esta, me sali√≥ el tiro por la culata\",\n",
        "    \"Si quer√©s algo bueno de verdad, esto es por donde va la cosa\"\n",
        "]"
      ],
      "metadata": {
        "id": "BXppflMyzLnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for frase in frases2:\n",
        "    print(f\"{frase} ‚Üí {sentiment(frase)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auGTh0zQzRm1",
        "outputId": "021aea3d-e2fd-41a4-8f3b-ddb30274a066"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pa' serte franco, esto est√° de novela, che ‚Üí [{'label': 'NEU', 'score': 0.8798360228538513}]\n",
            "Mir√°, esto es un desastre, ni al peor enemigo se lo recomiendo ‚Üí [{'label': 'NEG', 'score': 0.9989790916442871}]\n",
            "No est√° ni tan mal ni tan bien... como pa' zafar ‚Üí [{'label': 'POS', 'score': 0.9973741769790649}]\n",
            "Una joyita, lo digo con el coraz√≥n en la mano ‚Üí [{'label': 'POS', 'score': 0.9930917024612427}]\n",
            "Esto no tiene vuelta, fue un clavo tremendo ‚Üí [{'label': 'NEG', 'score': 0.9992641806602478}]\n",
            "Le ponen garra, se nota, eso vale m√°s que mil estrellas ‚Üí [{'label': 'NEG', 'score': 0.9731284976005554}]\n",
            "Una decepci√≥n b√°rbara, esperaba otra cosa ‚Üí [{'label': 'NEG', 'score': 0.998916745185852}]\n",
            "Est√° bueno, sencillo pero cumplidor, como tiene que ser ‚Üí [{'label': 'NEU', 'score': 0.9683693647384644}]\n",
            "Nunca m√°s caigo en esta, me sali√≥ el tiro por la culata ‚Üí [{'label': 'NEG', 'score': 0.999354898929596}]\n",
            "Si quer√©s algo bueno de verdad, esto es por donde va la cosa ‚Üí [{'label': 'NEU', 'score': 0.9753333330154419}]\n"
          ]
        }
      ]
    }
  ]
}
