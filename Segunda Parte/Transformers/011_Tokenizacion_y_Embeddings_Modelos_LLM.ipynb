{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b306d3e6",
      "metadata": {
        "id": "b306d3e6"
      },
      "source": [
        "# Explorando Tokenizaci칩n y Embeddings con Modelos de Lenguaje\n",
        "\n",
        "游눠 **NOTA**: Necesitaremos usar una GPU para ejecutar los ejemplos en este cuaderno.  \n",
        "En Google Colab, and치 a:  \n",
        "**Runtime > Change runtime type > Hardware accelerator > GPU > GPU type > T4**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "668c34d8",
      "metadata": {
        "id": "668c34d8"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install --upgrade pip\n",
        "!pip uninstall -y transformers accelerate\n",
        "!pip install transformers==4.41.2 accelerate==0.31.0 sentence-transformers==2.7.0 gensim==4.3.2 scikit-learn==1.5.0 numpy==1.26.4 scipy==1.13.1 pandas==2.0.3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e9fe11d",
      "metadata": {
        "id": "9e9fe11d"
      },
      "source": [
        "## Descargando y Ejecutando un LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "155775e2",
      "metadata": {
        "id": "155775e2"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"microsoft/Phi-3-mini-4k-instruct\",\n",
        "    device_map=\"cpu\",\n",
        "    torch_dtype=\"auto\",\n",
        "    trust_remote_code=False,\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")\n",
        "\n",
        "prompt = \"Escrib칤 un email disculp치ndote con Mar칤a por el incidente en el asado del domingo. Explic치 c칩mo sucedi칩.\"\n",
        "\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(\"cpu\")\n",
        "\n",
        "generation_output = model.generate(\n",
        "  input_ids=input_ids,\n",
        "  max_new_tokens=200\n",
        ")\n",
        "print(tokenizer.decode(generation_output[0]))\n",
        "\n",
        "generation_output = model.generate(\n",
        "  input_ids=input_ids,\n",
        "  max_new_tokens=100\n",
        ")\n",
        "print(tokenizer.decode(generation_output[0]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ba43103",
      "metadata": {
        "id": "3ba43103"
      },
      "source": [
        "## Comparando Tokenizadores de LLMs Entrenados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e19aef2",
      "metadata": {
        "id": "8e19aef2"
      },
      "outputs": [],
      "source": [
        "colors_list = [\n",
        "    '102;194;165', '252;141;98', '141;160;203',\n",
        "    '231;138;195', '166;216;84', '255;217;47'\n",
        "]\n",
        "\n",
        "def show_tokens(sentence, tokenizer_name):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
        "    token_ids = tokenizer(sentence).input_ids\n",
        "    for idx, t in enumerate(token_ids):\n",
        "        print(\n",
        "            f'\\x1b[0;30;48;2;{colors_list[idx % len(colors_list)]}m' +\n",
        "            tokenizer.decode(t) +\n",
        "            '\\x1b[0m',\n",
        "            end=' '\n",
        "        )\n",
        "\n",
        "text = \"\"\"\n",
        "Espa침ol y MAY칔SCULAS\n",
        "游븰 침\n",
        "show_tokens False None elif == >= else: dos tabs:\"    \" Tres tabs: \"       \"\n",
        "12.0*50=600\n",
        "El mate est치 muy caliente\n",
        "\"\"\"\n",
        "\n",
        "show_tokens(text, \"bert-base-uncased\")\n",
        "show_tokens(text, \"bert-base-cased\")\n",
        "show_tokens(text, \"microsoft/Phi-3-mini-4k-instruct\")\n",
        "show_tokens(text, \"gpt2\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32a6ac9d",
      "metadata": {
        "id": "32a6ac9d"
      },
      "source": [
        "## Embeddings de Palabras Contextualizados desde un Modelo de Lenguaje"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28e806a4",
      "metadata": {
        "id": "28e806a4"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-base\")\n",
        "model = AutoModel.from_pretrained(\"microsoft/deberta-v3-xsmall\")\n",
        "\n",
        "tokens = tokenizer('Hola mundo', return_tensors='pt')\n",
        "output = model(**tokens)[0]\n",
        "\n",
        "print(\"Forma del tensor de salida:\")\n",
        "print(output.shape)\n",
        "\n",
        "print(\"\\nTokens individuales:\")\n",
        "for token in tokens['input_ids'][0]:\n",
        "    print(tokenizer.decode(token))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install --force-reinstall numpy==1.26.4 scipy==1.13.1"
      ],
      "metadata": {
        "id": "Pox523KfiDme"
      },
      "id": "Pox523KfiDme",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "36a54b5e",
      "metadata": {
        "id": "36a54b5e"
      },
      "source": [
        "## Embeddings de Texto (Para Oraciones y Documentos Completos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f4c11bf",
      "metadata": {
        "id": "3f4c11bf"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
        "vector = model.encode(\"춰La mejor pel칤cula que vi!\")\n",
        "\n",
        "print(\"Dimensiones del vector:\", vector.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uWQgUhIziEGm"
      },
      "id": "uWQgUhIziEGm"
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}