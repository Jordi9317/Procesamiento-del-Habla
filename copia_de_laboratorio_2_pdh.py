# -*- coding: utf-8 -*-
"""Copia de Laboratorio 2 PDH.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wHLYGa-IsUt6tlPv34DNcK9m4hW0Ls4e
"""

import requests

from bs4 import BeautifulSoup

#Defino URL
url = 'https://www.gutenberg.org/cache/epub/74704/pg74704-images.html'

#Traigo el contenido de la URL y lo combierto a Text
contenido = requests.get(url).text

#Creo el objeto Soup
soup = BeautifulSoup(contenido, "html.parser")

#transformo en cadena de texto
parrafos = str(soup.find_all("p"))

from wordcloud import WordCloud
import numpy as np
from PIL import Image
import nltk
from nltk.corpus import stopwords
import re

import matplotlib.pyplot as plt

nltk.download('stopwords')
stopwords_es = set(stopwords.words('spanish'))

#funcion para limpiar texto
def limpiar_texto(texto):
  palabra_a_eliminar= ['dijo', 'así', 'aunque', 'sino', 'luego', 'pues', 'mientras',
        'después', 'antes', 'porque', 'cuando', 'cómo', 'donde', 'cap',
        'capítulo', 'verso', 'canto', 'á', 'ó','si','oh','allí','cuanto','cerca','parece','ay','p','quien','sido','dice','quién','dio','se','tan']

#Anexa las palabras que queremos eliminar a la lista de Stopwords
  black_list = stopwords_es.union(palabra_a_eliminar)
  texto_minuscula = texto.lower()
  texto_limpio = re.sub(r'[^\w\s]', '', texto_minuscula)
  palabras = texto_limpio.split()
  palabras_importantes =[]
  for palabra in palabras:
    if palabra not in black_list:
      palabras_importantes.append(palabra)
  return(palabras_importantes)

texto_completo = soup.get_text()
palabras_limpias = limpiar_texto(texto_completo)
texto_limpio = ' '.join(palabras_limpias)

!pip install spacy watermark -q

!python -m spacy download en_core_web_lg -q

import spacy
from spacy import displacy

#PIPILE DE SPACY
#Cargar el modelo
nlp = spacy.load("en_core_web_lg")
import en_core_web_lg
nlp = en_core_web_lg.load()

texto_ejemplo = texto_limpio

#Procesar el texto con Spacy
doc = nlp(texto_ejemplo)

tokens= [token.text for token in doc]
print(tokens)

# Lematizacion: forma base de cada token
for token in doc:
    # Ignoramos puntuación y espacios para mayor claridad
    if not token.is_punct and not token.is_space:
        print(f"'{token.text}' -> '{token.lemma_}'")

# Etiquetado gramatical
for token in doc:
    if not token.is_space: # Ignoramos espacios
        print(f"'{token.text}' -> {token.pos_} ({spacy.explain(token.pos_)}) -> {token.tag_}")

# Analisis de dependencia sintactica
for token in doc:
     if not token.is_space:
        print(f"'{token.text}' -> {token.dep_} ({spacy.explain(token.dep_)}) -> '{token.head.text}'")

displacy.render(doc, style='dep', jupyter=True, options={'distance': 120})

from collections import Counter

palabras_clave = []

for token in doc:
    if token.is_alpha and not token.is_stop:
      # Normalización: Obtener lema y convertir a minúsculas
      palabras_clave.append(token.lemma_.lower())

print(f"Se extrajeron {len(palabras_clave)} palabras clave (lemas, sin stop words).")
# Ejemplo de las primeras palabras extraídas:
print(f"Ejemplo: {palabras_clave[:15]}")

frecuencia_palabras = Counter(palabras_clave)

N = 15
palabras_mas_comunes = frecuencia_palabras.most_common(N)

for palabra, frecuencia in palabras_mas_comunes:
    print(f"- '{palabra}' : {frecuencia}")

from wordcloud import WordCloud
import matplotlib.pyplot as plt

wordcloud_generator = WordCloud(
    width=800,
    height=400,
    background_color='white',
    colormap='viridis', # Paleta de colores
    max_words=50,      # Mostrar máximo 50 palabras
    stopwords=None,    # Ya filtramos stop words antes
    collocations=False # Evitar que agrupe palabras (ej. "dióxido carbono")
                       # Si se quisiera, sería mejor hacerlo antes con Spacy/N-gramas
).generate_from_frequencies(frecuencia_palabras) # <-- Usar las frecuencias calculadas

plt.figure(figsize=(10, 5)) # Tamaño de la figura donde se mostrará
plt.imshow(wordcloud_generator, interpolation='bilinear') # Mostrar la imagen generada
plt.axis("off") # No mostrar los ejes X e Y
plt.tight_layout(pad=0) # Ajustar para que no haya bordes extra
plt.show() # <-- ¡Mostrar la ventana con la nube!

