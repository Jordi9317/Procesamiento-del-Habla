{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5ZVm6CIouwgF"
      },
      "outputs": [],
      "source": [
        "%pip install -U -q google-genai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Procesamiento de Lenguaje Natural con Google Gemini API\n",
        "Este script demuestra diversas aplicaciones de Procesamiento de Lenguaje Natural (PLN) utilizando el modelo Gemini de Google a través de la librería `google-generativeai`."
      ],
      "metadata": {
        "id": "KvvIHZvXyE2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "0xS2NWpqvWHX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "cliente = genai.Client(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "sL2CGPN7vvHj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definición del texto de entrada"
      ],
      "metadata": {
        "id": "Cy_bZVjVyTbE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Texto base que utilizaremos para todos los ejemplos.\n",
        "\n",
        "text_to_process = \"\"\"Estimado Amazon, la semana pasada pedí una figura de acción de Optimus Prime\n",
        "en su tienda en línea en Alemania. Desafortunadamente, cuando abrí el paquete,\n",
        "descubrí con horror que me habían enviado una figura de acción de Megatron\n",
        "en su lugar. Como enemigo de toda la vida de los Decepticons, espero que pueda\n",
        "entender mi dilema. Para resolver el problema, exijo un cambio de Megatron por\n",
        "la figura de Optimus Prime que pedí. Adjunto copias de mis registros relativos\n",
        "a esta compra. Espero tener noticias suyas pronto. Atentamente, Bumblebee.\"\"\"\n",
        "\n",
        "print(\"\\nTexto de entrada definido.\")"
      ],
      "metadata": {
        "id": "_NwHWVYpv_Ji",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec823aaf-cdeb-4396-eb82-16a4356da7ef"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Texto de entrada definido.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_ID = \"gemini-2.0-flash\" # @param [\"gemini-2.0-flash-lite\",\"gemini-2.0-flash\",\"gemini-2.5-flash-preview-05-20\",\"gemini-2.5-pro-preview-05-06\"] {\"allow-input\":true, isTemplate: true}"
      ],
      "metadata": {
        "id": "msa42Srs1Mci"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Sumarizacion"
      ],
      "metadata": {
        "id": "nR1SRBxf1Sma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pregunta = f\"\"\"Sumariza el siguiente texto en dos oraciones de rapida lectura\n",
        "\n",
        "Texto: {text_to_process}\n",
        "\"\"\"\n",
        "\n",
        "respuesta = cliente.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[pregunta] # Pasa la pregunta como contenido\n",
        ")\n",
        "print(respuesta.text)"
      ],
      "metadata": {
        "id": "zjLIg2OZ1Pby",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4303bdbb-ba8b-4f99-db4a-40cccbf2ee2a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bumblebee le escribe a Amazon para quejarse de haber recibido una figura de acción de Megatron en vez de la de Optimus Prime que había ordenado. Exige que le cambien a Megatron por la figura correcta y adjunta sus comprobantes de compra.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Clasificación de Sentimiento"
      ],
      "metadata": {
        "id": "A0XQRDI01INu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pregunta = f\"\"\"Clasificá el siguiente texto como positivo, negativo o neutral y explicá por qué:\n",
        "\n",
        "Texto: {text_to_process}\n",
        "\"\"\"\n",
        "\n",
        "respuesta = cliente.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[pregunta] # Pasa la pregunta como contenido\n",
        ")\n",
        "print(respuesta.text)"
      ],
      "metadata": {
        "id": "w59q68sb0og-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0f34cdf-a350-4f9f-a4b4-e35f5cda90c8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El texto es **negativo**.\n",
            "\n",
            "Aquí está la explicación:\n",
            "\n",
            "*   **Tono general:** El tono del correo electrónico es de decepción y frustración. El uso de palabras como \"desafortunadamente\" y \"con horror\" denotan emociones negativas.\n",
            "\n",
            "*   **Problema planteado:** El cliente recibió el producto incorrecto, lo cual es una experiencia negativa.\n",
            "\n",
            "*   **Exigencia:** El cliente exige una solución al problema, lo cual indica insatisfacción.\n",
            "\n",
            "Aunque el correo electrónico está escrito de manera cortés, el mensaje principal es sobre una experiencia negativa con un pedido.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. Reconocimiento de Entidades Nombradas (NER)"
      ],
      "metadata": {
        "id": "Eyjbk9Ij1mlD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"Extraé todas las entidades nombradas del siguiente texto (personas, organizaciones, lugares, objetos) y clasificálas:\n",
        "\n",
        "Texto: {text_to_process}\n",
        "\"\"\"\n",
        "\n",
        "respuesta = cliente.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[prompt] # Pasa la pregunta como contenido\n",
        ")\n",
        "print(respuesta.text)"
      ],
      "metadata": {
        "id": "0ZO0owXo1nqM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bf507c1-ff85-4119-f179-f716111062d7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Claro, aquí están las entidades nombradas extraídas del texto, clasificadas por tipo:\n",
            "\n",
            "*   **Organizaciones:**\n",
            "    *   Amazon\n",
            "    *   Decepticons\n",
            "*   **Personas:**\n",
            "    *   Bumblebee\n",
            "*   **Lugares:**\n",
            "    *   Alemania\n",
            "*   **Objetos:**\n",
            "    *   Optimus Prime (figura de acción)\n",
            "    *   Megatron (figura de acción)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4. Respuesta a preguntas (Question Answering)"
      ],
      "metadata": {
        "id": "R7nLX8XA2ARy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pregunta = \"¿Qué producto recibió el cliente?\"\n",
        "contexto = text_to_process\n",
        "\n",
        "prompt = f\"\"\"Respondé la siguiente pregunta basada en el texto:\n",
        "\n",
        "Texto: {contexto}\n",
        "Pregunta: {pregunta}\n",
        "\"\"\"\n",
        "\n",
        "respuesta = cliente.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[contexto, pregunta] # Pasa la pregunta como contenido\n",
        ")\n",
        "print(respuesta.text)\n"
      ],
      "metadata": {
        "id": "_OJB5YkV2B0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e16b756d-3035-494d-f6e0-0e6adbe4535c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El cliente recibió una figura de acción de Megatron.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5. Resumen automático"
      ],
      "metadata": {
        "id": "teUpLbTm2iah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"Resumí el siguiente texto en no más de 3 líneas:\n",
        "\n",
        "Texto: {text_to_process}\n",
        "\"\"\"\n",
        "\n",
        "respuesta = cliente.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[prompt] # Pasa la pregunta como contenido\n",
        ")\n",
        "print(respuesta.text)\n"
      ],
      "metadata": {
        "id": "eU1ntrhI2iIC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b14ba2b5-8325-466a-ce40-c6d52bdc9e09"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bumblebee recibió una figura de Megatron en lugar de la figura de Optimus Prime que había pedido a Amazon Alemania. Exige un cambio por el artículo correcto y adjuntó pruebas de su compra. Espera una pronta respuesta para solucionar el problema.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6. Traducción (Español a Inglés)"
      ],
      "metadata": {
        "id": "tnd7hnBo254-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"Traducí al inglés este texto:\n",
        "\n",
        "Texto: {text_to_process}\n",
        "\"\"\"\n",
        "\n",
        "respuesta = cliente.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[prompt] # Pasa la pregunta como contenido\n",
        ")\n",
        "print(respuesta.text)\n"
      ],
      "metadata": {
        "id": "txSjXi-w2zOL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e942fe5-8521-41b9-be7e-b8f64a833cb2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Okay, here's the translation:\n",
            "\n",
            "Dear Amazon,\n",
            "\n",
            "Last week I ordered an Optimus Prime action figure from your online store in Germany. Unfortunately, when I opened the package, I discovered to my horror that I had been sent a Megatron action figure instead. As a lifelong enemy of the Decepticons, I hope you can understand my dilemma. To resolve the issue, I demand an exchange of the Megatron for the Optimus Prime figure that I ordered. I have attached copies of my records pertaining to this purchase. I look forward to hearing from you soon.\n",
            "\n",
            "Sincerely,\n",
            "\n",
            "Bumblebee.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##7. Generación de respuesta (como atención al cliente)"
      ],
      "metadata": {
        "id": "n2ODoTLy3Cp9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "respuesta_inicial = \"Estimado cliente, lamentamos mucho lo ocurrido con su pedido. \"\n",
        "\n",
        "prompt = f\"\"\"{text_to_process}\n",
        "\n",
        "Redactá una respuesta del servicio de atención al cliente que comience así:\n",
        "\n",
        "\"{respuesta_inicial}\"\n",
        "\n",
        "Cuya extension no supere las 4 lineas.\n",
        "\"\"\"\n",
        "\n",
        "respuesta = cliente.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[prompt] # Pasa la pregunta como contenido\n",
        ")\n",
        "print(respuesta.text)"
      ],
      "metadata": {
        "id": "WmAhcje23CTG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70c16b76-6bef-49b7-c4d0-ceb7d28e0b38"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimado cliente, lamentamos mucho lo ocurrido con su pedido. Entendemos su frustración por recibir la figura de Megatron en lugar de la de Optimus Prime. Por favor, acepte nuestras disculpas. Procederemos a enviarle la figura correcta de Optimus Prime y le daremos instrucciones para devolver la figura de Megatron sin costo alguno para usted.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##8. Clasificación Zero-Shot (sin entrenamiento previo)"
      ],
      "metadata": {
        "id": "dtVjz8gr3VGR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "etiquetas = [\"queja\", \"elogio\", \"consulta\", \"pedido\", \"agradecimiento\"]\n",
        "\n",
        "prompt = f\"\"\"Clasificá el siguiente texto en una de estas categorías: {', '.join(etiquetas)}. Justificá tu elección.\n",
        "\n",
        "Texto: {text_to_process}\n",
        "\"\"\"\n",
        "\n",
        "respuesta = cliente.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[prompt] # Pasa la pregunta como contenido\n",
        ")\n",
        "print(respuesta.text)\n"
      ],
      "metadata": {
        "id": "UtHlUvEy3URy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88a87437-8399-4fe8-addf-0d434b50eed0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Clasificación: Queja**\n",
            "\n",
            "**Justificación:**\n",
            "\n",
            "El texto es claramente una **queja** por los siguientes motivos:\n",
            "\n",
            "*   **Expresa insatisfacción:** Bumblebee manifiesta su \"horror\" al recibir un producto incorrecto (Megatron en lugar de Optimus Prime). Esto indica un sentimiento de decepción y descontento.\n",
            "*   **Describe un problema:** El texto detalla un error en el pedido, especificando el producto incorrecto recibido.\n",
            "*   **Solicita una solución:** Bumblebee \"exige\" un cambio del producto erróneo por el que originalmente ordenó, mostrando su intención de resolver el problema.\n",
            "*   **Incluye evidencia:** La mención de adjuntar copias de los registros de compra refuerza la validez de la queja.\n",
            "\n",
            "Todos estos elementos en conjunto señalan que el propósito principal del texto es expresar una inconformidad y buscar una solución a un error cometido por Amazon.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EJERCICIO\n",
        "\n",
        "Escribí un texto corto sobre una experiencia personal en un transporte público en Buenos Aires.\n",
        "\n",
        "Luego, generá:\n",
        "\n",
        "- Un resumen.\n",
        "- Una clasificación de sentimiento.\n",
        "- Una lista de entidades nombradas."
      ],
      "metadata": {
        "id": "nOPQ22a63k0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Texto base que utilizaremos para todos los ejemplos.\n",
        "\n",
        "text_to_process1 = \"\"\"Tomé el colectivo 60 una mañana de lluvia.\n",
        "Como siempre, venía lleno, y el parabrisas empañado hacía que el chofer manejara casi por instinto.\n",
        "Me agarré como pude del caño, esquivando mochilas y paraguas cerrados que goteaban sobre el piso.\n",
        "Una señora mayor me sonrió al ver que le cedí el asiento, y me agradeció con ese “gracias, nene” que te acomoda el día.\n",
        "A pesar del apuro y el caos típico de la ciudad, hubo algo cálido en ese gesto mínimo. Un recordatorio de que, incluso en el bondi apretado, hay lugar para la humanidad.\"\"\"\n",
        "\n",
        "print(\"\\nTexto de entrada definido.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AP49bO3LE2U",
        "outputId": "580a8ce9-ae98-48b6-c965-e3343a8fd856"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Texto de entrada definido.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resumen"
      ],
      "metadata": {
        "id": "Zyg9e9BDMa6d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"Resumí el siguiente texto en no más de 3 líneas:\n",
        "\n",
        "Texto: {text_to_process1}\n",
        "\"\"\"\n",
        "\n",
        "respuesta = cliente.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[prompt] # Pasa la pregunta como contenido\n",
        ")\n",
        "print(respuesta.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsm8YCPqMKqa",
        "outputId": "876bd054-fcfb-4505-b187-9556f53438ec"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "En un colectivo 60 lleno y lluvioso, el narrador cede su asiento a una señora mayor. Su agradecimiento conmovió al narrador en medio del caos urbano. La experiencia demostró que la amabilidad persiste incluso en las situaciones más cotidianas.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clasificación de sentimiento"
      ],
      "metadata": {
        "id": "WOjE3oFDMhZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "etiquetas = [\"queja\", \"elogio\", \"consulta\", \"pedido\", \"agradecimiento\"]\n",
        "\n",
        "prompt = f\"\"\"Clasificá el siguiente texto en una de estas categorías: {', '.join(etiquetas)}. Justificá tu elección.\n",
        "\n",
        "Texto: {text_to_process1}\n",
        "\"\"\"\n",
        "\n",
        "respuesta = cliente.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[prompt] # Pasa la pregunta como contenido\n",
        ")\n",
        "print(respuesta.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkzmq05TLmiE",
        "outputId": "ea4fb894-e9b4-49aa-8d77-d5bbaf17316c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La categoría que mejor describe el texto es **elogio**.\n",
            "\n",
            "**Justificación:**\n",
            "\n",
            "Si bien el texto menciona aspectos negativos como el colectivo lleno, el parabrisas empañado y la incomodidad del viaje, el foco principal está en resaltar un aspecto positivo: la calidez humana. El autor enfatiza el gesto de la señora mayor y cómo ese simple agradecimiento tuvo un impacto positivo en su día.\n",
            "\n",
            "*   **No es una queja:** Aunque menciona dificultades, no hay un reclamo directo o una expresión de insatisfacción hacia un servicio o persona en particular.\n",
            "*   **No es una consulta:** No hay ninguna pregunta planteada en el texto.\n",
            "*   **No es un pedido:** No se solicita nada al lector ni a ninguna entidad.\n",
            "*   **No es un agradecimiento:** El autor no está agradeciendo a nadie en particular, sino que reflexiona sobre un acto de agradecimiento que recibió.\n",
            "\n",
            "El texto celebra un acto de bondad y destaca la importancia de la humanidad en la vida cotidiana, lo que lo convierte en un elogio a la conexión humana y a los pequeños gestos que pueden mejorar el día de alguien.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lista de entidades nombradas"
      ],
      "metadata": {
        "id": "EgmZYFypM8rL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"Extraé todas las entidades nombradas del siguiente texto (personas, organizaciones, lugares, objetos) y clasificálas:\n",
        "\n",
        "Texto: {text_to_process1}\n",
        "\"\"\"\n",
        "\n",
        "respuesta = cliente.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[prompt] # Pasa la pregunta como contenido\n",
        ")\n",
        "print(respuesta.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_DPk4KjL0fk",
        "outputId": "cfe4a4ba-efaa-407e-f2a8-b33b05ca9c56"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*   **60:** (Objeto - Línea de colectivo)\n",
            "*   **Bondi:** (Objeto - Colectivo)\n",
            "*   **Ciudad:** (Lugar - Ciudad)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o5G2oaymMIo1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}