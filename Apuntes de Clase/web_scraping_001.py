# -*- coding: utf-8 -*-
"""web_scraping_001.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nVHuKpXwJDo0teEtiYRcUFLxxLB-nxEk

## Caso 1
"""

import requests

from bs4 import BeautifulSoup

url = "https://www.gutenberg.org/cache/epub/58221/pg58221-images.html"

contenido = requests.get(url).text

print(type(contenido))

soup = BeautifulSoup(contenido, "html.parser")

h1 = soup.find_all("h1")

print(h1)

italicas = soup.find_all("i")

print(italicas)

from collections import Counter

parrafos = str(soup.find_all("p"))

print(parrafos.count("Ulises"))
print(parrafos.count("Ciclope"))
print(parrafos.count("Minerva"))

# Funcion para buscar palabras
def buscar_palabra(palabra):
  ocurrencias = str(soup).lower().count(palabra.lower())
  print(f"Encontraste la plabra '{palabra}' {ocurrencias} veces")

buscar_palabra("Ulises")

import random

parrafo = soup.find_all("p")
parrafo_aleatorio = random.choice(parrafo).text.strip()

print(parrafo_aleatorio)

print(len(parrafo_aleatorio.split()))

from wordcloud import WordCloud
import numpy as np
from PIL import Image
import nltk
from nltk.corpus import stopwords
import re

import matplotlib.pyplot as plt

# Descarga corpus de stopwords en español
nltk.download('stopwords')
stopwords_es = set(stopwords.words('spanish'))

# Funcion para limpiar texto

def limpiar_texto(texto):

  texto_minuscula = texto.lower() # convierte todo el texto en minusculas

  texto_sin_puntuacion = re.sub(r'[^\w\s]', '', texto_minuscula) # elimina todos los signos de puntuacion

  lista_palabras = texto_sin_puntuacion.split() # divide el texto en palabras individuales

  palabras_importantes = [] # crea lista de palabras importantes

  for palabra in lista_palabras:
    if palabra not in stopwords_es:
      palabras_importantes.append(palabra)

  return palabras_importantes

texto_completo = soup.get_text()

palabras_limpias = limpiar_texto(texto_completo)

texto_limpio = ' '.join(palabras_limpias)

wordcloud = WordCloud(width=800, height=400, background_color='white').generate(texto_limpio)

plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.show()

colores_personalizados = ['#FF0000', '#00FF00', '#0000FF']  # Rojo, verde, azul
wordcloud = WordCloud(width=800, height=400, background_color='white', color_func=lambda word, font_size, position, orientation, random_state=None, **kwargs: random.choice(colores_personalizados)).generate(texto_limpio)

plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.show()

# Funcion para limpiar texto

def limpiar_texto(texto):

# Lista de palabras a eliminar

  palabras_a_eliminar = ['dijo', 'así', 'aunque', 'sino', 'luego', 'pues', 'mientras',
        'después', 'antes', 'porque', 'cuando', 'cómo', 'donde', 'cap',
        'capítulo', 'verso', 'canto', 'á', 'ó', 'si']

# Añexa las palabras que quiero eliminar a las stopwords

  black_list = stopwords_es.union(palabras_a_eliminar)

  texto_minuscula = texto.lower() # convierte todo el texto en minusculas

  texto_sin_puntuacion = re.sub(r'[^\w\s]', '', texto_minuscula) # elimina todos los signos de puntuacion

  lista_palabras = texto_sin_puntuacion.split() # divide el texto en palabras individuales

  palabras_importantes = [] # crea lista de palabras importantes

  for palabra in lista_palabras:
    if palabra not in black_list:
      palabras_importantes.append(palabra)

  return palabras_importantes

texto_completo = soup.get_text()

palabras_limpias = limpiar_texto(texto_completo)

texto_limpio = ' '.join(palabras_limpias)

wordcloud = WordCloud(width=800, height=400, background_color="black", colormap = "inferno").generate(texto_limpio)

plt.figure(figsize=(20, 5))
plt.imshow(wordcloud, interpolation="bilinear")
plt.axis("off")
plt.show()

"""## Caso 2

Defino la URL
"""

url_2 = "https://stackoverflow.com/questions/415511/how-to-get-the-current-time-in-python"

"""Trae el contenido de la URL"""

pagina = requests.get(url_2)

contenido = pagina.text

"""Creo el objeto soup"""

soup = BeautifulSoup(contenido, "html.parser")

pregunta = soup.find("div", {"class": "question"})
texto_pregunta = pregunta.find("div", {"class": "s-prose js-post-body"})

print(texto_pregunta.get_text().strip())

respuesta = soup.find("div", {"class": "answer"})
texto_respuesta = respuesta.find("div", {"class": "s-prose js-post-body"})
print(texto_respuesta.get_text().strip())